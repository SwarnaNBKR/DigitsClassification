{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchvision) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:13<00:00, 709kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 92.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:12<00:00, 129kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 14.8kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data= datasets.MNIST( root=\"data\", train=True, download=True, transform=ToTensor(),)\n",
    "test_data=datasets.MNIST( root=\"data\", train=False, download=True, transform=ToTensor(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N,C,H, W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y:torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_dataloader=DataLoader(training_data,batch_size=batch_size)\n",
    "test_dataloader=DataLoader(test_data,batch_size=batch_size)\n",
    "\n",
    "for X,y in test_dataloader:\n",
    "    print(f\"Shape of X [N,C,H, W]:{X.shape}\")\n",
    "    print(f\"Shape of y:{y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_image(image, label):\n",
    "    plt.imshow(image.squeeze(),cmap='gray')\n",
    "    plt.title(f\"label:{label}\")\n",
    "    plt.show()\n",
    "show_image(X[0],y[0])\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
       "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
       "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.33 0.73 0.62 0.59 0.24 0.14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.87 1.00 1.00 1.00 1.00 0.95 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.78 0.67 0.20 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.26 0.45 0.28 0.45 0.64 0.89 1.00 0.88 1.00 1.00 1.00 0.98 0.90 1.00 1.00 0.55 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 0.26 0.05 0.26 0.26 0.26 0.23 0.08 0.93 1.00 0.42 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.33 0.99 0.82 0.07 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.09 0.91 1.00 0.33 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.51 1.00 0.93 0.17 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.23 0.98 1.00 0.24 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.52 1.00 0.73 0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.04 0.80 0.97 0.23 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.49 1.00 0.71 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.29 0.98 0.94 0.22 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 0.87 1.00 0.65 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.80 1.00 0.86 0.14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.15 1.00 1.00 0.30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.12 0.88 1.00 0.45 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.52 1.00 1.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.24 0.95 1.00 1.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.47 1.00 1.00 0.86 0.16 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.47 1.00 0.81 0.07 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n"
     ]
    }
   ],
   "source": [
    "x=X[0].squeeze()\n",
    "for row in x:\n",
    "    for item in row:\n",
    "        print(\"{:.2f}\".format(item.item()),end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "x=X[0].squeeze()\n",
    "for row in x:\n",
    "    for item in row:\n",
    "        pixel=0\n",
    "        if item.item()>0:\n",
    "            pixel=1\n",
    "        print(pixel,end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "# get gpu,cpu, or mps device for training\n",
    "device=(\n",
    "    \"cuda\" \n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\")\n",
    "print(f\"using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 784])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "p1= nn.Flatten()(x) # .to(device)\n",
    "print(p1.shape)\n",
    "p2=nn.Linear(28*28,512)(p1) # here (p1) or .to(device)(p1)\n",
    "print(p2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "          )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0333, -0.0154, -0.0366,  0.0292,  0.0152,  0.0017,  0.0277, -0.0652,\n",
       "         -0.0084, -0.0500]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first test of correctness to do if the architecture is defined properly\n",
    "x=X[:1].to(device)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0min_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mout_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Applies an affine linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
      "\n",
      "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "\n",
      "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      "\n",
      "Args:\n",
      "    in_features: size of each input sample\n",
      "    out_features: size of each output sample\n",
      "    bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "        Default: ``True``\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
      "      dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
      "    - Output: :math:`(*, H_{out})` where all but the last dimension\n",
      "      are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      "\n",
      "Attributes:\n",
      "    weight: the learnable weights of the module of shape\n",
      "        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "        :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "            If :attr:`bias` is ``True``, the values are initialized from\n",
      "            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> m = nn.Linear(20, 30)\n",
      "    >>> input = torch.randn(128, 20)\n",
      "    >>> output = m(input)\n",
      "    >>> print(output.size())\n",
      "    torch.Size([128, 30])\n",
      "\u001b[1;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\swarn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     NonDynamicallyQuantizableLinear, LazyLinear, Linear, LinearBn1d, Linear"
     ]
    }
   ],
   "source": [
    "?nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 784])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for layer in model.parameters():\n",
    "    print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0123,  0.0329,  0.0157,  ..., -0.0138,  0.0018,  0.0007],\n",
       "        [ 0.0113,  0.0306, -0.0038,  ..., -0.0160, -0.0230, -0.0321],\n",
       "        [-0.0119, -0.0162, -0.0183,  ..., -0.0034, -0.0132,  0.0349],\n",
       "        ...,\n",
       "        [-0.0205,  0.0324, -0.0342,  ..., -0.0267,  0.0328,  0.0227],\n",
       "        [ 0.0106,  0.0188, -0.0317,  ...,  0.0322, -0.0056,  0.0133],\n",
       "        [ 0.0337, -0.0075,  0.0085,  ..., -0.0075, -0.0160,  0.0227]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.parameters():\n",
    "    break\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.linear_relu_stack[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.SGD(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0333, -0.0154, -0.0366,  0.0292,  0.0152,  0.0017,  0.0277, -0.0652,\n",
      "         -0.0084, -0.0500]], grad_fn=<AddmmBackward0>) torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "pred=model(x)\n",
    "print(pred, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3548, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(x), y[:1].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size=len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss=loss_fn(pred,y)\n",
    "\n",
    "        #Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d} / {size:>5d}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches=len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss,correct=0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X, y=X.to(device), y.to(device)\n",
    "            pred=model(X)\n",
    "            test_loss+=loss_fn(pred,y).item()\n",
    "            correct+= (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg Loss:{test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 12.5%, Avg Loss:2.301315 \n",
      "\n",
      "Epoch1\n",
      " -----------------\n",
      "loss:2.299552 [   64 / 60000]\n",
      "loss:2.293033 [ 6464 / 60000]\n",
      "loss:2.294460 [12864 / 60000]\n",
      "loss:2.288852 [19264 / 60000]\n",
      "loss:2.276909 [25664 / 60000]\n",
      "loss:2.271679 [32064 / 60000]\n",
      "loss:2.266359 [38464 / 60000]\n",
      "loss:2.284918 [44864 / 60000]\n",
      "loss:2.258504 [51264 / 60000]\n",
      "loss:2.262559 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg Loss:2.254894 \n",
      "\n",
      "Epoch2\n",
      " -----------------\n",
      "loss:2.252757 [   64 / 60000]\n",
      "loss:2.244662 [ 6464 / 60000]\n",
      "loss:2.255038 [12864 / 60000]\n",
      "loss:2.227196 [19264 / 60000]\n",
      "loss:2.227009 [25664 / 60000]\n",
      "loss:2.223202 [32064 / 60000]\n",
      "loss:2.205196 [38464 / 60000]\n",
      "loss:2.238274 [44864 / 60000]\n",
      "loss:2.195682 [51264 / 60000]\n",
      "loss:2.195572 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg Loss:2.189152 \n",
      "\n",
      "Epoch3\n",
      " -----------------\n",
      "loss:2.185946 [   64 / 60000]\n",
      "loss:2.172419 [ 6464 / 60000]\n",
      "loss:2.197605 [12864 / 60000]\n",
      "loss:2.134426 [19264 / 60000]\n",
      "loss:2.148252 [25664 / 60000]\n",
      "loss:2.144224 [32064 / 60000]\n",
      "loss:2.105963 [38464 / 60000]\n",
      "loss:2.160148 [44864 / 60000]\n",
      "loss:2.091978 [51264 / 60000]\n",
      "loss:2.085682 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg Loss:2.077725 \n",
      "\n",
      "Epoch4\n",
      " -----------------\n",
      "loss:2.072327 [   64 / 60000]\n",
      "loss:2.048201 [ 6464 / 60000]\n",
      "loss:2.098935 [12864 / 60000]\n",
      "loss:1.978998 [19264 / 60000]\n",
      "loss:2.010226 [25664 / 60000]\n",
      "loss:2.002668 [32064 / 60000]\n",
      "loss:1.937002 [38464 / 60000]\n",
      "loss:2.024033 [44864 / 60000]\n",
      "loss:1.914892 [51264 / 60000]\n",
      "loss:1.901102 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg Loss:1.886658 \n",
      "\n",
      "Epoch5\n",
      " -----------------\n",
      "loss:1.880418 [   64 / 60000]\n",
      "loss:1.836840 [ 6464 / 60000]\n",
      "loss:1.922523 [12864 / 60000]\n",
      "loss:1.733844 [19264 / 60000]\n",
      "loss:1.775203 [25664 / 60000]\n",
      "loss:1.758880 [32064 / 60000]\n",
      "loss:1.672521 [38464 / 60000]\n",
      "loss:1.805044 [44864 / 60000]\n",
      "loss:1.642964 [51264 / 60000]\n",
      "loss:1.623563 [57664 / 60000]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg Loss:1.598281 \n",
      "\n",
      "done in  47.98960542678833 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "epochs = 5\n",
    "test(test_dataloader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch{t+1}\\n -----------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"done in \",time.time()-start,\"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
